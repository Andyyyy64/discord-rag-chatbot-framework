import type { Client, TextChannel } from 'discord.js';

import {
  createMessageFetcher,
  type FetchedMessage,
} from '../../infrastructure/discord/message-fetcher';
import { logger } from '../../infrastructure/logging/logger';
import { getSupabaseClient } from '../../infrastructure/supabase/client';
import type { TypedSyncOperation } from '../../infrastructure/supabase/database-extensions.types';
import { createBaseError } from '../../shared/errors/base-error';
import type { DiscordMessage } from '../common/chunking';
import { createChunkingService } from '../common/chunking-service';

type SyncOperationRow = TypedSyncOperation;

export interface SyncRunnerConfig {
  pollIntervalMs?: number;
}

/**
 * åŒæœŸã‚¸ãƒ§ãƒ–ã‚’å‡¦ç†ã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼
 */
export function createSyncRunner(client: Client, config: SyncRunnerConfig = {}) {
  const supabase = getSupabaseClient();
  const fetcher = createMessageFetcher(client);
  const chunkingService = createChunkingService();
  const pollIntervalMs = config.pollIntervalMs ?? 5000;

  /**
   * queued çŠ¶æ…‹ã®ã‚¸ãƒ§ãƒ–ã‚’1ã¤å–å¾—ã—ã¦ãƒ­ãƒƒã‚¯
   */
  const acquireJob = async (): Promise<SyncOperationRow | null> => {
    const { data, error } = await supabase
      .from('sync_operations')
      .select('*')
      .eq('status', 'queued')
      .order('created_at', { ascending: true })
      .limit(1)
      .maybeSingle<SyncOperationRow>();

    if (error) {
      logger.error('Failed to acquire job', error);
      return null;
    }

    if (!data) return null;

    // ã‚¸ãƒ§ãƒ–ã‚’ running ã«æ›´æ–°
    const { error: updateError } = await supabase
      .from('sync_operations')
      .update({
        status: 'running',
        updated_at: new Date().toISOString(),
      })
      .eq('id', data.id);

    if (updateError) {
      logger.error('Failed to update job status to running', updateError);
      return null;
    }

    return data;
  };

  /**
   * ã‚¸ãƒ§ãƒ–ã®é€²æ—ã‚’æ›´æ–°
   */
  const updateProgress = async (
    jobId: string,
    processed: number,
    total: number,
    message?: string
  ): Promise<void> => {
    const { error } = await supabase
      .from('sync_operations')
      .update({
        progress: { processed, total, message },
        updated_at: new Date().toISOString(),
      })
      .eq('id', jobId);

    if (error) {
      logger.error('Failed to update progress', error);
    }
  };

  /**
   * ã‚¸ãƒ§ãƒ–ã‚’å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
   */
  const completeJob = async (jobId: string, success: boolean, errorMsg?: string): Promise<void> => {
    const { error } = await supabase
      .from('sync_operations')
      .update({
        status: success ? 'completed' : 'failed',
        progress: success
          ? { processed: 100, total: 100, message: 'âœ… åŒæœŸå®Œäº†ã—ã¾ã—ãŸï¼' }
          : { processed: 0, total: 0, message: errorMsg ?? 'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ' },
        updated_at: new Date().toISOString(),
      })
      .eq('id', jobId);

    if (error) {
      logger.error('Failed to complete job', error);
    }
  };

  /**
   * åŸ‹ã‚è¾¼ã¿å‡¦ç†ã®å®Œäº†ã‚’å¾…æ©Ÿ
   */
  const waitForEmbeddingComplete = async (guildId: string, jobId: string): Promise<void> => {
    const maxWaitTime = 30 * 60 * 1000; // 30åˆ†
    const pollInterval = 5000; // 5ç§’
    const startTime = Date.now();
    let consecutiveErrors = 0;
    const maxConsecutiveErrors = 3;

    while (Date.now() - startTime < maxWaitTime) {
      try {
        // readyçŠ¶æ…‹ã®embed_queueã‚’å–å¾—
        const { data: queueData, error: queryError } = await supabase
          .from('embed_queue')
          .select('window_id')
          .eq('status', 'ready');

        if (queryError) {
          throw queryError;
        }

        if (!queueData || queueData.length === 0) {
          logger.info('All embeddings completed');
          return;
        }

        // windowsãŒå¯¾è±¡ã‚®ãƒ«ãƒ‰ã®ã‚‚ã®ã‹ãƒã‚§ãƒƒã‚¯
        const windowIds = queueData.map((q) => q.window_id);

        // ãƒãƒƒãƒã§ãƒã‚§ãƒƒã‚¯ï¼ˆ500ä»¶ãšã¤ï¼‰
        let remainingCount = 0;
        const batchSize = 500;

        for (let i = 0; i < windowIds.length; i += batchSize) {
          const batch = windowIds.slice(i, i + batchSize);
          const { count, error: batchError } = await supabase
            .from('message_windows')
            .select('window_id', { count: 'exact', head: true })
            .eq('guild_id', guildId)
            .in('window_id', batch);

          if (batchError) {
            logger.warn(`Failed to check batch ${i / batchSize + 1}`, batchError);
            continue;
          }

          remainingCount += count || 0;
        }

        if (remainingCount === 0) {
          logger.info('All embeddings completed for guild');
          return;
        }

        logger.info(`Waiting for embeddings: ${remainingCount} remaining`);
        await updateProgress(jobId, 90, 100, `âœ¨ åŸ‹ã‚è¾¼ã¿å‡¦ç†ä¸­ (æ®‹ã‚Š${remainingCount}ä»¶)...`);

        // ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
        consecutiveErrors = 0;
      } catch (error) {
        consecutiveErrors++;
        logger.warn(
          `Failed to check embed queue status (${consecutiveErrors}/${maxConsecutiveErrors})`,
          error
        );

        // é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹å ´åˆã¯ã€å®Œäº†ã¨è¦‹ãªã™
        if (consecutiveErrors >= maxConsecutiveErrors) {
          logger.warn('Too many consecutive errors, assuming embeddings are complete');
          return;
        }
      }

      await new Promise((resolve) => setTimeout(resolve, pollInterval));
    }

    logger.warn('Embedding wait timeout, continuing anyway...');
  };

  /**
   * ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
   */
  const saveMessages = async (
    guildId: string,
    messages: Array<{
      id: string;
      channelId: string;
      threadId?: string;
      authorId: string;
      content: string;
      createdAt: Date;
      editedAt?: Date;
    }>
  ): Promise<void> => {
    if (messages.length === 0) return;

    // messages ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ï¼ˆupsertï¼‰
    const rows = messages.map((msg) => ({
      guild_id: guildId,
      channel_id: msg.channelId,
      thread_id: msg.threadId ?? null,
      message_id: msg.id,
      author_id: msg.authorId,
      content_plain: msg.content,
      content_md: msg.content,
      created_at: msg.createdAt.toISOString(),
      edited_at: msg.editedAt?.toISOString() ?? null,
      jump_link: `https://discord.com/channels/${guildId}/${msg.channelId}/${msg.id}`,
    }));

    // ãƒãƒƒãƒã§ä¿å­˜
    const batchSize = 50;
    const totalBatches = Math.ceil(rows.length / batchSize);
    let savedCount = 0;

    for (let i = 0; i < rows.length; i += batchSize) {
      const batch = rows.slice(i, i + batchSize);
      const batchNum = Math.floor(i / batchSize) + 1;

      let retries = 0;
      const maxRetries = 3;

      while (retries <= maxRetries) {
        try {
          const { error } = await supabase.from('messages').upsert(batch, {
            onConflict: 'message_id',
            ignoreDuplicates: false,
          });

          if (error) {
            throw error;
          }

          savedCount += batch.length;
          logger.info(
            `  â†’ Saved batch ${batchNum}/${totalBatches} (${savedCount}/${rows.length} messages)`
          );
          break;
        } catch (error) {
          retries++;
          if (retries > maxRetries) {
            logger.error(`Failed to save batch ${batchNum} after ${maxRetries} retries`, error);
            throw createBaseError('ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ', 'MESSAGE_SAVE_FAILED', {
              error,
            });
          }

          const waitTime = Math.pow(2, retries) * 1000;
          logger.warn(
            `  â†’ Batch ${batchNum} failed, retrying in ${waitTime}ms (attempt ${retries}/${maxRetries})`,
            error
          );
          await new Promise((resolve) => setTimeout(resolve, waitTime));
        }
      }
    }

    logger.info(`Saved ${messages.length} messages to database`);
  };

  /**
   * ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–ã—ã¦ message_windows ã¨ embed_queue ã«ä¿å­˜
   */
  const createWindows = async (
    guildId: string,
    messages: Array<{
      id: string;
      channelId: string;
      threadId?: string;
      content: string;
      createdAt: Date;
    }>
  ): Promise<void> => {
    if (messages.length === 0) return;

    // ã‚«ãƒ†ã‚´ãƒª â†’ ãƒãƒ£ãƒ³ãƒãƒ« â†’ æ—¥ä»˜ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    const groups = new Map<string, typeof messages>();

    for (const msg of messages) {
      const dateKey = msg.createdAt.toISOString().split('T')[0];
      const channelKey = msg.threadId ?? msg.channelId;
      const key = `${channelKey}:${dateKey}`;

      if (!groups.has(key)) {
        groups.set(key, []);
      }
      groups.get(key)!.push(msg);
    }

    let totalWindows = 0;

    // å„ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
    for (const [key, groupMessages] of groups) {
      const [_channelKey, dateStr] = key.split(':');
      const isThread = groupMessages[0].threadId !== undefined;

      // DiscordMessage å½¢å¼ã«å¤‰æ›
      const discordMessages: DiscordMessage[] = groupMessages.map((msg) => ({
        id: msg.id,
        content: msg.content,
        createdAt: msg.createdAt,
        isTopLevel: !isThread, // ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã¯ false
      }));

      // ãƒãƒ£ãƒ³ã‚¯åŒ–
      const windows = await chunkingService.chunk(discordMessages);

      if (windows.length === 0) continue;

      // message_windows ã«ä¿å­˜
      const windowRows = windows.map((window) => ({
        guild_id: guildId,
        channel_id: groupMessages[0].channelId,
        thread_id: groupMessages[0].threadId ?? null,
        date: dateStr,
        window_seq: window.windowSeq,
        message_ids: window.messageIds,
        start_at: window.startAt.toISOString(),
        end_at: window.endAt.toISOString(),
        token_est: window.tokenCount,
        text: window.text,
      }));

      const { data: insertedWindows, error: windowError } = await supabase
        .from('message_windows')
        .upsert(windowRows, {
          onConflict: 'channel_id,date,window_seq',
          ignoreDuplicates: false,
        })
        .select('window_id');

      if (windowError) {
        logger.error('Failed to save message windows', windowError);
        throw createBaseError('ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ', 'WINDOW_SAVE_FAILED', {
          error: windowError,
        });
      }

      // embed_queue ã«æŠ•å…¥
      if (insertedWindows && insertedWindows.length > 0) {
        const queueRows = insertedWindows.map((w) => ({
          window_id: w.window_id,
          priority: 0,
          status: 'ready',
        }));

        const { error: queueError } = await supabase.from('embed_queue').upsert(queueRows, {
          onConflict: 'window_id',
          ignoreDuplicates: true,
        });

        if (queueError) {
          logger.warn('Failed to enqueue windows for embedding', queueError);
        } else {
          totalWindows += insertedWindows.length;
        }
      }
    }

    logger.info(
      `âœ“ Created ${totalWindows} windows from ${groups.size} channel-date groups and enqueued for embedding`
    );
  };

  /**
   * 1ã¤ã®ã‚¸ãƒ§ãƒ–ã‚’å‡¦ç†
   */
  const processJob = async (job: SyncOperationRow): Promise<void> => {
    logger.info(`Processing sync job: ${job.id} (scope: ${job.scope}, mode: ${job.mode})`);

    try {
      // é€²æ—ã‚’åˆæœŸåŒ–
      await updateProgress(job.id, 0, 1, 'åŒæœŸã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...');

      // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ï¼ˆé€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
      const since = job.since ? new Date(job.since) : undefined;
      
      let messages: FetchedMessage[] = [];

      // ã‚¹ã‚³ãƒ¼ãƒ—ã«å¿œã˜ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—
      if (job.scope === 'channel' && job.target_ids && job.target_ids.length > 0) {
        // ãƒãƒ£ãƒ³ãƒãƒ«åŒæœŸ
        const channelId = job.target_ids[0];
        logger.info(
          `Starting message fetch from channel ${channelId} (since: ${since?.toISOString() ?? 'beginning'})`
        );

        const guild = client.guilds.cache.get(job.guild_id);
        if (!guild) {
          throw new Error(`Guild ${job.guild_id} not found`);
        }

        const channel = await guild.channels.fetch(channelId);
        if (!channel || !channel.isTextBased()) {
          throw new Error(`Channel ${channelId} not found or is not a text channel`);
        }

        await updateProgress(job.id, 10, 100, `ğŸ“¥ ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ä¸­...`);
        messages = await fetcher.fetchMessagesFromChannel(channel as TextChannel, { since });
        logger.info(`âœ“ Fetched ${messages.length} messages from channel ${channelId}`);
      } else {
        // ã‚®ãƒ«ãƒ‰å…¨ä½“ã®åŒæœŸ
        logger.info(
          `Starting message fetch from guild ${job.guild_id} (since: ${since?.toISOString() ?? 'beginning'})`
        );

        messages = await fetcher.fetchMessagesFromGuild(job.guild_id, {
          since,
          onProgress: async (completed, total, phase) => {
            // ãƒ•ã‚§ãƒ¼ã‚º1: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—ï¼ˆå…¨ä½“ã®0-30%ï¼‰
            const percentage = Math.floor((completed / total) * 30);
            await updateProgress(
              job.id,
              percentage,
              100,
              `ğŸ“¥ ${phase}: ${completed}/${total}ãƒãƒ£ãƒ³ãƒãƒ«`
            );
          },
        });

        logger.info(`âœ“ Fetched ${messages.length} messages from guild ${job.guild_id}`);
      }

      if (messages.length === 0) {
        await completeJob(job.id, true);
        return;
      }

      // ãƒ•ã‚§ãƒ¼ã‚º2: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ï¼ˆ30-50%ï¼‰
      await updateProgress(job.id, 30, 100, `ğŸ’¾ ${messages.length}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ä¸­...`);
      logger.info(`Saving ${messages.length} messages to database...`);

      await saveMessages(job.guild_id, messages);
      logger.info(`âœ“ Saved ${messages.length} messages`);

      // ãƒ•ã‚§ãƒ¼ã‚º3: ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼ˆ50-90%ï¼‰
      await updateProgress(job.id, 50, 100, `ğŸ”¨ ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ä¸­...`);
      logger.info(`Starting chunking for ${messages.length} messages...`);

      await createWindows(job.guild_id, messages);
      logger.info(`âœ“ Chunking complete`);

      // ãƒ•ã‚§ãƒ¼ã‚º4: åŸ‹ã‚è¾¼ã¿å‡¦ç†ã‚’å¾…æ©Ÿï¼ˆ90-99%ï¼‰
      await updateProgress(job.id, 90, 100, 'âœ¨ åŸ‹ã‚è¾¼ã¿å‡¦ç†ä¸­...');
      logger.info('Waiting for embedding to complete...');

      await waitForEmbeddingComplete(job.guild_id, job.id);
      logger.info(`âœ“ Embedding complete`);

      // ãƒ•ã‚§ãƒ¼ã‚º5: ã‚«ãƒ¼ã‚½ãƒ«æ›´æ–°ï¼ˆ99-100%ï¼‰
      await updateProgress(job.id, 99, 100, 'ğŸ”„ ã‚«ãƒ¼ã‚½ãƒ«æ›´æ–°ä¸­...');

      const { error: cursorError } = await supabase.from('sync_cursors').upsert({
        guild_id: job.guild_id,
        last_synced_at: new Date().toISOString(),
        last_message_id: messages[messages.length - 1]?.id ?? null,
      });

      if (cursorError) {
        logger.warn('Failed to update sync cursor', cursorError);
      }

      // å®Œäº†
      await completeJob(job.id, true);
      logger.info(`Sync job ${job.id} completed successfully`);
    } catch (error) {
      logger.error(`Sync job ${job.id} failed`, error);
      await completeJob(job.id, false, String(error));
    }
  };

  /**
   * ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’é–‹å§‹ï¼ˆãƒãƒ¼ãƒªãƒ³ã‚°ï¼‰
   */
  const start = async (): Promise<void> => {
    logger.info('Sync runner started');

    while (true) {
      try {
        const job = await acquireJob();

        if (job) {
          await processJob(job);
        } else {
          // ã‚¸ãƒ§ãƒ–ãŒãªã„å ´åˆã¯å¾…æ©Ÿ
          await new Promise((resolve) => setTimeout(resolve, pollIntervalMs));
        }
      } catch (error) {
        logger.error('Sync runner error', error);
        await new Promise((resolve) => setTimeout(resolve, pollIntervalMs));
      }
    }
  };

  return {
    start,
    processJob,
  };
}
